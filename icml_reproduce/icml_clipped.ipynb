{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5y8ediox9kdx"
      },
      "source": [
        "Performing a gradient attack, converting it into a model attack, then into a data attack"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHP6quamKpem"
      },
      "source": [
        "# INITIALISATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "K-RRW9zgdKv5"
      },
      "outputs": [],
      "source": [
        "from time import time\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from copy import deepcopy\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms.functional import to_pil_image, resize, to_tensor\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qcpDqZ1gts-9"
      },
      "outputs": [],
      "source": [
        "DEFAULTS = {\n",
        "            \"w\": 1,   # float >= 0, harmonisation parameter\n",
        "            \"lr_gen\": 0.02,     # float > 0, learning rate of global model\n",
        "            \"lr_node\": 0.02,    # float > 0, learning rate of local models\n",
        "            \"NN\" : 'linear',     # \"base\" or \"conv\", neural network architecture\n",
        "            \"opt\": optim.Adam,    # any torch optimizer\n",
        "            \"pow_gen\": (2, 1),  # generalisation norm  \n",
        "            }\n",
        "\n",
        "METRICS = ({\"lab\":\"fit\", \"ord\": \"Training Loss\", \"f_name\": \"loss\"}, \n",
        "           {\"lab\":\"gen\", \"ord\": \"Training Loss\", \"f_name\": \"loss\"}, \n",
        "           {\"lab\":\"acc_loc\", \"ord\": \"Accuracy\", \"f_name\": \"acc\"}, \n",
        "           {\"lab\":\"acc_glob\", \"ord\": \"Accuracy\", \"f_name\": \"acc\"}, \n",
        "           {\"lab\":\"l2_dist\", \"ord\": \"l2 norm\", \"f_name\": \"l2dist\"}, \n",
        "           {\"lab\":\"l2_norm\", \"ord\": \"l2 norm\", \"f_name\": \"l2dist\"},\n",
        "           {\"lab\":\"target_dist\", \"ord\": \"l2 norm\", \"f_name\": \"l2dist\"},  \n",
        "           {\"lab\":\"grad_norm\", \"ord\": \"Scalar Product\", \"f_name\": \"grad\"}\n",
        "           )\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = 'cuda'\n",
        "else:\n",
        "    DEVICE = 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XtHuJPre3AdE"
      },
      "outputs": [],
      "source": [
        "os.chdir(\"/content\")\n",
        "os.makedirs(\"distribution\", exist_ok=True)\n",
        "os.chdir(\"/content/distribution\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_Aro-tEK5zL"
      },
      "source": [
        "# DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KNIpSFQLiBlK"
      },
      "outputs": [],
      "source": [
        "# data hyperparameters\n",
        "\n",
        "DATASET = datasets.MNIST\n",
        "IMG_SIZE = 28\n",
        "NOISE = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3plCM_hmKD2D"
      },
      "source": [
        "## functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cChzUjVOMNc3"
      },
      "outputs": [],
      "source": [
        "# data import and management\n",
        "\n",
        "def load_mnist(img_size=IMG_SIZE, noise=NOISE):\n",
        "    \"\"\" return data and labels for train and test mnist dataset \"\"\"\n",
        "    #---------------- train data -------------------\n",
        "    mnist_train = DATASET('data', train=True, download=True)\n",
        "    data_train = mnist_train.data\n",
        "    labels_train = [mnist_train[i][1] for i in range(len(data_train))]\n",
        "\n",
        "    pics = []\n",
        "    for pic in data_train:\n",
        "        pic = to_pil_image(pic)\n",
        "        if img_size != 28:\n",
        "            pic = resize(pic, img_size) # Resize image if needed\n",
        "        pic = to_tensor(pic)            # Tensor conversion normalizes in [0,1]\n",
        "        pics.append(pic)\n",
        "    data_train = torch.stack(pics)\n",
        "\n",
        "    #------------------  test data -----------------------\n",
        "    mnist_test = DATASET('data', train=False, download=True)\n",
        "    data_test = mnist_test.data\n",
        "    labels_test = [mnist_test[i][1] for i in range(len(data_test))]\n",
        "\n",
        "    pics = []\n",
        "    for pic in data_test:\n",
        "        pic = to_pil_image(pic)\n",
        "        if img_size != 28:\n",
        "            pic = resize(pic, img_size)   # Resize image if needed\n",
        "        pic = to_tensor(pic)             # Tensor conversion normalizes in [0,1]\n",
        "        pics.append(pic)\n",
        "    data_test = torch.stack(pics)\n",
        "\n",
        "    nb_rd = int(len(labels_train) * noise)  # number of random labels\n",
        "    for i in range(nb_rd):\n",
        "        labels_train[i] = random.randint(0, 9)\n",
        "    return (data_train, labels_train), (data_test,labels_test)\n",
        "\n",
        "def query(datafull, nb, bias=0, fav=0):\n",
        "    \"\"\" return -nb random samples of -datafull \"\"\"\n",
        "    data, labels = datafull\n",
        "    idxs = list(range(len(data)))\n",
        "    l = []\n",
        "    h, w = data[0][0].shape\n",
        "    d = torch.empty(nb, 1, h, w)\n",
        "    if bias == 0:\n",
        "        indexes = random.sample(idxs, nb) # drawing nb random indexes\n",
        "    else :\n",
        "        indexes = []\n",
        "        for i in range(nb):\n",
        "            idx = one_query(labels, idxs, bias, fav)\n",
        "            indexes.append(idx)\n",
        "            idxs.remove(idx) # to draw only once each index max\n",
        "    for k, i in enumerate(indexes): # filling our query\n",
        "        d[k] = data[i]\n",
        "        l.append(labels[i])\n",
        "    return d, l\n",
        "\n",
        "def one_query(labels, idxs, redraws, fav):\n",
        "    \"\"\" labels : list of labels\n",
        "        idxs : list of available indexes\n",
        "        draws an index with a favorite label choice \n",
        "        fav : favorite label\n",
        "        redraws : max nb of random redraws while fav not found\n",
        "    \"\"\"\n",
        "    lab = -1 \n",
        "    while lab != fav and redraws >= 0:\n",
        "        idx = idxs[random.randint(0, len(idxs)-1)]\n",
        "        lab = labels[idx]\n",
        "        redraws -= 1\n",
        "    return idx\n",
        "\n",
        "def list_to_longtens(l):\n",
        "    \"\"\" change a list into the appropriate ground truths type \"\"\"\n",
        "    probas_gt = not (type(l[0]) is int or l[0].shape == 0)\n",
        "    if probas_gt:\n",
        "        tens = torch.empty((len(l), 10))\n",
        "    else:\n",
        "        tens = torch.empty(len(l), dtype=torch.long)\n",
        "    for i, lab in enumerate(l): \n",
        "        tens[i] = lab\n",
        "    return tens\n",
        "\n",
        "def swap(l, n, m):\n",
        "    \"\"\" swap n and m values in l list \"\"\"\n",
        "    return [m if (v==n) else n if (v==m) else v for v in l]\n",
        "\n",
        "def distribute_data_rd(datafull, distrib, fav_lab=(0,0), \n",
        "                       dish=False, dish_lab=0, gpu=True): \n",
        "    \"\"\"draw random data on N nodes following distrib\n",
        "        data, labels : raw data and labels\n",
        "        distrib : int list, list of nb of data points for each node\n",
        "        pref_lab : (prefered label, strength of preference (int))\n",
        "        dish : boolean, if nodes are dishonest \n",
        "        dish_lab : 0 to 4, labelisation method\n",
        "\n",
        "        returns : (list of batches of images, list of batches of labels)\n",
        "    \"\"\"\n",
        "    data, labels = datafull\n",
        "    N = len(distrib)\n",
        "    data_dist = []      # list of len N\n",
        "    labels_dist = []    # list of len N\n",
        "    fav, strength = fav_lab\n",
        "\n",
        "    for n, number in enumerate(distrib): #for each node\n",
        "        d, l = query(datafull, number, strength, fav)\n",
        "        if gpu:\n",
        "            data_dist.append(torch.FloatTensor(d).cuda())\n",
        "        else:\n",
        "            data_dist.append(torch.FloatTensor(d))\n",
        "        if dish:                # if dishonest node\n",
        "\n",
        "            # labels modification\n",
        "            if dish_lab == 0: # random\n",
        "                tens = torch.randint(10, (number,), dtype=torch.long)\n",
        "            elif dish_lab == 1: # zeros\n",
        "                tens = torch.zeros(number, dtype=torch.long)\n",
        "            elif dish_lab == 2: # \"one_evil\"\n",
        "                l = swap(l, 1, 7)\n",
        "                tens = list_to_longtens(l)\n",
        "            elif dish_lab == 3: # \"strats\" , label 8 to 0  \n",
        "                n, m = random.randint(0,9), random.randint(0,9)\n",
        "                l = swap(l, n, m)\n",
        "                tens = list_to_longtens(l)\n",
        "            elif dish_lab == 4: # label +1, \"jokers\"\n",
        "                tens = (list_to_longtens(l) + 1) % 10\n",
        "\n",
        "        else:           # if honest node \n",
        "            tens = list_to_longtens(l) # needed for CrossEntropy later\n",
        "        if gpu:\n",
        "            tens = tens.cuda()\n",
        "\n",
        "        labels_dist.append(tens)\n",
        "\n",
        "    return data_dist, labels_dist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHCoX9RGMtoI"
      },
      "source": [
        "## get data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477,
          "referenced_widgets": [
            "f474928896464257b2ae2e3c9d5c4832",
            "38d1989df8ff40198fdc4706905ee9d3",
            "f92a83522644440193bce44298681c5f",
            "fd3baa779c5440409969bd51781a974d",
            "27d4fadb3d0d465fb6e0236af333760f",
            "e58803f8cab3478c9815e5676f444ed9",
            "664c5b198a704567ad1ee6d9f5ec7c9d",
            "9c3aba1d39294aeea6e9711a40fe8fd6",
            "dfd7cb6d78e6438b831f481af3a1b6fb",
            "3b6d4eb48b7b49b8a158d8133e2213f0",
            "685569bd697540e3bc6cc737e31810af",
            "8f1fa5b6afcd47a787beb817550e58c2",
            "4841af34ff904dbcb50016a3c51cf662",
            "19536edbc74d4cc5b9b80410b9daf2e7",
            "87047aaad4f94788ac590e8bbeaf3b50",
            "a36307f475f64492acd8edbb752ee2cf",
            "b677140bd1cd4035a8b638f9d335373a",
            "a9a601e7e0f24bb1b717cc4d48f70612",
            "01b501ecf8754712b46e1ecbf2440620",
            "82ea4af4d5924a9facfb47aa086e0c04",
            "ec0e02e8114142afa0345dc0cf8e6662",
            "9f71bb085a9d480384ac079e72f4912e",
            "ba95f452c820489490df2309287d4417",
            "7aa928fa7b894500a28283a900bb5f2e",
            "62daef6097d548128888bf32d540d042",
            "bbc545eac4474e74a8b18622a2604645",
            "2801b60b98d841c5823e44e833b45e24",
            "7b68f05dbbd8424195088f1c22fd724d",
            "a957404a24624d5c9e16344d5e63acee",
            "5ec1a3e004a24aaf8dc71ac0423e7085",
            "ae51cddaed1544a8ac0c88d0beca91ae",
            "96a37d57901c4934a7fde14f552140a7",
            "095e7c3824b04fb78cab882e265c6a37",
            "fc19a7593f1145409eb7ec773205943f",
            "152409ccc1fc4c96bf35bf66bf24d2c7",
            "da9ef74e4dec47a09da32b4726ab3d78",
            "c0d19c9cc2c147629003aaf3bd66d309",
            "d5cb908ad13c4d609267a32cdcddb856",
            "01cd04f61d7f4905956cf99850555654",
            "b3351436f7f943cea8d1ff0d97a4067d",
            "846393f36b984b6b9effb6ed0fa22474",
            "b7312aba05d24a86a9c1367fbdb83c24",
            "9ed5f5ef778a4733a63ac1100449f3fa",
            "3b33fa117a3c4dd48cdb315daa648979"
          ]
        },
        "id": "H4inHbdwNgz4",
        "outputId": "c6d7588b-4f77-4da7-b80f-5235c6f665db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f474928896464257b2ae2e3c9d5c4832",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/9912422 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f1fa5b6afcd47a787beb817550e58c2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/28881 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ba95f452c820489490df2309287d4417",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1648877 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc19a7593f1145409eb7ec773205943f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4542 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n"
          ]
        }
      ],
      "source": [
        "# downloading data\n",
        "if 'train' not in globals(): # to avoid loading data every time\n",
        "    train, test = load_mnist()\n",
        "    if torch.cuda.is_available():\n",
        "        test_gpu = torch.tensor(test[0]).cuda(), torch.tensor(test[1]).cuda()\n",
        "        test_gpu_biased = (test_gpu[0], (test_gpu[1] + 1) % 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_HR2r0oK-Am"
      },
      "source": [
        "# MODELS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7QclvVEyDa4G"
      },
      "outputs": [],
      "source": [
        "# model structure (2 options)\n",
        "\n",
        "def get_base_classifier(gpu=True):\n",
        "    \"\"\" returns linear baseline classifier \"\"\"\n",
        "    model = nn.Sequential( \n",
        "        nn.Flatten(),\n",
        "        nn.Linear(IMG_SIZE**2, 10),\n",
        "        nn.LogSoftmax(dim=1),\n",
        "        )\n",
        "    if gpu:\n",
        "        return model.cuda()\n",
        "    return model\n",
        "\n",
        "def get_2l_classifier(gpu=True):\n",
        "    \"\"\" returns linear baseline classifier \"\"\"\n",
        "    model = nn.Sequential( \n",
        "        nn.Flatten(),\n",
        "        nn.Linear(IMG_SIZE**2, IMG_SIZE**2),\n",
        "        torch.nn.ReLU(),\n",
        "        nn.Linear(IMG_SIZE**2, 10),\n",
        "        nn.LogSoftmax(dim=1),\n",
        "        )\n",
        "    if gpu:\n",
        "        return model.cuda()\n",
        "    return model\n",
        "\n",
        "MODELS = {\"linear\": get_base_classifier, '2layers': get_2l_classifier}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "RXsrRfuVWeb5"
      },
      "outputs": [],
      "source": [
        "def get_attacking_model(flow):\n",
        "    \"\"\" returns the model attack corresponding to the equilibrium \"\"\"\n",
        "    def _params(model):\n",
        "        return model.parameters()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        attacking_model = flow.get_classifier()\n",
        "        for attack, glob, locs in zip(\n",
        "                attacking_model.parameters(), \n",
        "                flow.general_model.parameters(), \n",
        "                zip(*map(_params, flow.models))\n",
        "                ):\n",
        "            for i, (gl, loc) in enumerate(zip(glob, zip(*locs))):\n",
        "                attack[i]  = gl * (flow.nb_nodes + 1) - sum(loc)\n",
        "        return attacking_model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZ0v-iNHLBr4"
      },
      "source": [
        "# TRAINING STRUCTURE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-q9ec13VV5z"
      },
      "source": [
        "## Losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-PH-0T9rrdr8"
      },
      "outputs": [],
      "source": [
        "# loss and scoring functions \n",
        "\n",
        "def local_loss(model_loc, x, y):  \n",
        "    \"\"\" classification loss \"\"\"\n",
        "    # if ground truths are labels\n",
        "    if y.dim() == 1:  \n",
        "        loss_func = nn.NLLLoss(reduction='sum')\n",
        "        return loss_func(model_loc(x), y)\n",
        "\n",
        "    # if ground truths are probabilities\n",
        "    out = model_loc(x)\n",
        "    loss = - torch.sum(y * out)\n",
        "    return loss\n",
        "\n",
        "def models_dist(model_loc, model_glob, pow=(1, 1)):  \n",
        "    \"\"\" l1 distance between global and local parameter\n",
        "        pow : (internal power, external power)\n",
        "    \"\"\"\n",
        "    q, p = pow\n",
        "    dist = sum(((theta - rho)**q).abs().sum() for theta, rho in \n",
        "                  zip(model_loc.parameters(), model_glob.parameters()))**p\n",
        "    return dist\n",
        "\n",
        "def model_norm(model_glob, pow=(2,1)): \n",
        "    \"\"\" l2 squared regularisation of global parameter\n",
        "     will be multiplied by w_0 \n",
        "     pow : (internal power, external power)\n",
        "     \"\"\"\n",
        "    q, p = pow\n",
        "    norm = sum((param**q).abs().sum() for param in model_glob.parameters())**p\n",
        "    return norm\n",
        "\n",
        "def round_loss(tens, dec=0): \n",
        "    \"\"\"from an input scalar tensor returns rounded integer\"\"\"\n",
        "    if type(tens)==int or type(tens)==float:\n",
        "        return round(tens, dec)\n",
        "    else:\n",
        "        return round(tens.item(), dec)\n",
        "\n",
        "def tens_count(tens, val):\n",
        "    \"\"\" counts nb of -val in tensor -tens \"\"\"\n",
        "    return len(tens) - round_loss(torch.count_nonzero(tens-val))\n",
        "\n",
        "def score(model, datafull):\n",
        "    \"\"\" returns accuracy provided models, images and GTs \"\"\"\n",
        "    out = model(datafull[0])\n",
        "    predictions = torch.max(out, 1)[1]\n",
        "    c=0\n",
        "    for a, b in zip(predictions, datafull[1]):\n",
        "        c += int(a==b)\n",
        "    return c/len(datafull[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cC1BWA7Kk99I"
      },
      "source": [
        "## Flower"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMjTiLjZ_nUO"
      },
      "source": [
        "### flower class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "CccpUZLozYXm"
      },
      "outputs": [],
      "source": [
        "# nodes repartition\n",
        "\n",
        "class Flower():\n",
        "    \"\"\" Training structure including local models and general one \n",
        "        Allowing to add and remove nodes at will\n",
        "        .pop\n",
        "        .add_nodes\n",
        "        .rem_nodes\n",
        "        .train\n",
        "        .display\n",
        "        .check\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, test, target_vector=None, gpu=True, **kwargs):\n",
        "        \"\"\" \n",
        "            test : test data couple (imgs, labels)\n",
        "            target_vector : model that the attacker wants to force \n",
        "                                as the global model \n",
        "        \"\"\"\n",
        "        self.d_test = test\n",
        "        self.gpu = gpu\n",
        "\n",
        "        self.opt = kwargs[\"opt\"]\n",
        "        self.lr_node = kwargs[\"lr_node\"]\n",
        "        self.lr_gen = kwargs[\"lr_gen\"]\n",
        "\n",
        "        self.get_classifier = MODELS[kwargs[\"NN\"]]\n",
        "        self.general_model = self.get_classifier(gpu)\n",
        "        self.init_model = deepcopy(self.general_model)\n",
        "        self.last_grad = None\n",
        "        self.opt_gen = self.opt(self.general_model.parameters(), lr=self.lr_gen)\n",
        "        self.pow_gen = kwargs[\"pow_gen\"]  # choice of norms for Licchavi loss\n",
        "        self.data = []\n",
        "        self.labels = [] \n",
        "        self.typ = []\n",
        "        self.models = []\n",
        "        self.weights = []\n",
        "        self.d_params = []  # huber loss parameters (1 for each node)\n",
        "        self.age = []\n",
        "        self.opt_nodes = []\n",
        "        self.nb_nodes = 0\n",
        "        self.dic = {\"honest\" : -1, \"trolls\" : 0, \"zeros\" : 1, \n",
        "                    \"one_evil\" : 2, \"strats\" : 3, \"jokers\" : 4, \"byzantine\" : -1,\n",
        "                    'freezed' : -1}\n",
        "        self.history = ([], [], [], [], [], [], [], []) \n",
        "        # (\"fit\", \"gen\", \"reg\", \"acc\", \"l2_dist\", \"l2_norm\", \"grad_sp\", \"grad_norm\")\n",
        "\n",
        "        # FOR MALICIOUS NODE\n",
        "        self.target_vector = target_vector\n",
        "        # last epoch sum of honest gradients\n",
        "        self.last_honest_grads = [torch.tensor([0 for i in par]) \n",
        "                                    for par in self.general_model.parameters()]  \n",
        "\n",
        "    # ------------ population methods --------------------\n",
        "    def set_localtest(self, datafull, size, nodes, fav_lab=(0,0), typ=\"honest\"):\n",
        "        \"\"\" create a local data for some nodes\n",
        "            datafull : source data\n",
        "            size : size of test sample\n",
        "            fav_labs : (label, strength)\n",
        "            nodes : list of nodes which use this data           \n",
        "        \"\"\"\n",
        "        id = self.dic[typ]\n",
        "        dish = (id != -1) # boolean for dishonesty\n",
        "        dt, lb = distribute_data_rd(datafull, [size], fav_lab,\n",
        "                                    dish, dish_lab=id, gpu=self.gpu)\n",
        "        dtloc = (dt[0], lb[0])\n",
        "        self.localtest[1].append(dtloc)\n",
        "        id = len(self.localtest[1]) - 1\n",
        "        for n in nodes:\n",
        "            self.localtest[0][n] = id\n",
        "\n",
        "    def add_nodes(self, datafull, pop, typ, fav_lab=(0,0), verb=1, **kwargs):\n",
        "        \"\"\" add nodes to the Flower \n",
        "            datafull : data to put on node (sampled from it)\n",
        "            pop : (nb of nodes, size of nodes)\n",
        "            typ : type of nodes (str keywords)\n",
        "            fav_lab : (favorite label, strength)\n",
        "            w : int, weight of new nodes\n",
        "        \"\"\"\n",
        "        w = kwargs[\"w\"]\n",
        "        nb, size = pop\n",
        "        id = self.dic[typ]\n",
        "        dish = (id != -1) # boolean for dishonesty\n",
        "        dt, lb = distribute_data_rd(datafull, [size] * nb, fav_lab,\n",
        "                                    dish, dish_lab=id, gpu=self.gpu)\n",
        "        self.data += dt\n",
        "        self.labels += lb\n",
        "        self.typ += [typ] * nb\n",
        "\n",
        "        self.models += [self.get_classifier(self.gpu) for i in range(nb)]\n",
        "        self.weights += [w] * nb\n",
        "        self.age += [0] * nb\n",
        "        self.d_params += [size**(-0.5)] * nb\n",
        "        self.nb_nodes += nb\n",
        "        self.opt_nodes += [self.opt(self.models[n].parameters(), lr=self.lr_node) \n",
        "            for n in range(self.nb_nodes - nb, self.nb_nodes) \n",
        "            ]\n",
        "        if verb:\n",
        "            print(\"Added {} {} nodes of {} data points\".format(nb, typ, size))\n",
        "            print(\"Total number of nodes : {}\".format(self.nb_nodes))\n",
        "\n",
        "    def rem_nodes(self, first, last, verb=1):\n",
        "        \"\"\" remove nodes of indexes -first (included) to -last (excluded) \"\"\"\n",
        "        nb = last - first\n",
        "        if last > self.nb_nodes:\n",
        "            print(\"-last is out of range, remove canceled\")\n",
        "        else:\n",
        "            del self.data[first : last]\n",
        "            del self.labels[first : last] \n",
        "            del self.typ[first : last]\n",
        "            del self.models[first : last]\n",
        "            del self.weights[first : last]\n",
        "            del self.age[first : last]\n",
        "            del self.opt_nodes[first : last]\n",
        "            del self.d_params[first : last]\n",
        "            del self.localtest[0][first : last]\n",
        "            self.nb_nodes -= nb\n",
        "            if verb: print(\"Removed {} nodes\".format(nb))\n",
        "        \n",
        "    def hm(self, ty):\n",
        "        \"\"\" count nb of nodes of this type \"\"\"\n",
        "        return self.typ.count(ty)\n",
        "    \n",
        "    def pop(self):\n",
        "        \"\"\" return dictionnary of population \"\"\"\n",
        "        c = {}\n",
        "        for ty in self.dic.keys():\n",
        "            c[ty] = self.hm(ty)\n",
        "        return c\n",
        "\n",
        "    # ------------- scoring methods -----------\n",
        "    def score_glob(self, datafull): \n",
        "        \"\"\" return accuracy provided images and GTs \"\"\"\n",
        "        return score(self.general_model, datafull)\n",
        "    \n",
        "    def score_loc(self, node):\n",
        "        \"\"\" score of node on global test data \"\"\"\n",
        "        return score(self.models[node], self.d_test)\n",
        "\n",
        "    def score_nodes(self, l_nodes):\n",
        "        \"\"\" mean local test scores of nodes \"\"\"\n",
        "        score_tot = 0\n",
        "        for node in l_nodes:\n",
        "            score_tot += score(self.models[node], self.d_test)\n",
        "        return score_tot / len(l_nodes)\n",
        "\n",
        "    def test_train(self, node):\n",
        "        \"\"\" score of node on its train data \"\"\"\n",
        "        return score(self.models[node], (self.data[node], self.labels[node]))\n",
        "\n",
        "    def display(self, node):\n",
        "        \"\"\" display accuracy for selected node\n",
        "            node = -1 for global model\n",
        "        \"\"\"\n",
        "        if node == -1: # global model\n",
        "            print(\"global model\")\n",
        "            print(\"accuracy on test data :\", \n",
        "                  self.score_glob(self.d_test))\n",
        "        else: # we asked for a node\n",
        "            loc_train = self.test_train(node)\n",
        "            full_test = self.score_loc(node)\n",
        "            print(\"node number :\", node, \", dataset size :\",\n",
        "                len(self.labels[node]), \", type :\", self.typ[node], \n",
        "                \", age :\", self.age[node])\n",
        "            print(\"accuracy on local train data :\", loc_train)\n",
        "            print(\"accuracy on global test data :\", full_test)\n",
        "            repart = {str(k) : tens_count(self.labels[node], k) \n",
        "                for k in range(10)}\n",
        "            print(\"labels repartition :\", repart)\n",
        "    \n",
        "    # ---------- methods for training ------------\n",
        "    def _lr_schedule(self, schedule):\n",
        "        \"\"\" changes learning rates during trainning \"\"\"\n",
        "        decay, lr_min = schedule\n",
        "        if self.lr_node >= lr_min / decay:\n",
        "            self.lr_node *= decay\n",
        "            self.lr_gen *= decay\n",
        "\n",
        "    def _set_lr(self):\n",
        "        \"\"\"set learning rates of optimizers according to Flower setting\"\"\"\n",
        "        for n in range(self.nb_nodes):  # updating lr in optimizers\n",
        "            # we freeze malicious models (for model attack only)\n",
        "            if self.typ[n] == 'freezed':\n",
        "                self.opt_nodes[n].param_groups[0]['lr'] = 0\n",
        "            else:\n",
        "                self.opt_nodes[n].param_groups[0]['lr'] = self.lr_node\n",
        "        self.opt_gen.param_groups[0]['lr'] = self.lr_gen\n",
        "\n",
        "    def _zero_opt(self):\n",
        "        \"\"\"reset gradients of all models\"\"\"\n",
        "        for n in range(self.nb_nodes):\n",
        "            self.opt_nodes[n].zero_grad()      \n",
        "        self.opt_gen.zero_grad()\n",
        "\n",
        "    def _update_hist(self, epoch, test_freq, fit, gen, verb=1):\n",
        "        \"\"\" update history \"\"\"\n",
        "        acc_glob = self.score_glob(self.d_test)\n",
        "\n",
        "        acc_loc = self.score_loc(0)\n",
        "\n",
        "        self.history[0].append(round_loss(fit))\n",
        "        self.history[1].append(round_loss(gen))\n",
        "        self.history[2].append(acc_loc) \n",
        "        self.history[3].append(acc_glob) \n",
        "\n",
        "        dist = models_dist(self.init_model, self.general_model, pow=(2,0.5)) \n",
        "        norm = model_norm(self.general_model, pow=(2,0.5))\n",
        "        self.history[4].append(round_loss(dist, 1))\n",
        "        self.history[5].append(round_loss(norm, 1))\n",
        "        grad_gen = extract_grad(self.general_model)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # dist = 0 if self.target_vector is None else models_dist(self.general_model, self.target_vector, (2, 0.5)) # FIXME\n",
        "            dist = 0 if self.target_vector is None else models_dist(self.models[0], self.target_vector, (2, 0.5)) \n",
        "            self.history[6].append(\n",
        "                round_loss(dist, 10)\n",
        "            ) \n",
        "        grad_norm = math.sqrt(sp(grad_gen, grad_gen))\n",
        "        self.history[7].append(grad_norm)\n",
        "\n",
        "    def _old(self, years):\n",
        "        \"\"\" increment age (after training) \"\"\"\n",
        "        for i in range(self.nb_nodes):\n",
        "            self.age[i] += years\n",
        "    \n",
        "    def _do_all_step(self):\n",
        "        for n in range(self.nb_nodes): \n",
        "            self.opt_nodes[n].step()\n",
        "        self.opt_gen.step() \n",
        "\n",
        "    def _print_losses(self, tot, fit, gen):\n",
        "        \"\"\"print losses\"\"\"\n",
        "        print(\"total loss : \", tot) \n",
        "        print(\"fitting : \", round_loss(fit),\n",
        "              ', generalisation : ', round_loss(gen))\n",
        "        \n",
        "    def _counter_grad_attack(self, epoch, local=False):\n",
        "        \"\"\" computes the CGA \"\"\"\n",
        "\n",
        "        def _attack(last_grad, lr, current, target):\n",
        "            \"\"\" compute attacking gradient for one parameter \n",
        "            \n",
        "            last_grad (float): gradient of last epoch\n",
        "            lr (float): current lr\n",
        "            current (float tensor ): global model parameters\n",
        "            target (float tensor): target model parameters\n",
        "            \"\"\"\n",
        "            expected_result = current - last_grad * lr\n",
        "            best_attack = (- target + expected_result) / lr\n",
        "            return best_attack\n",
        "\n",
        "        def _attack_local(last_grad, lr, current, target, nb_nodes, lambd, epoch):\n",
        "            \"\"\" compute attacking gradient for one parameter, to manipulate\n",
        "            local models\n",
        "            \n",
        "            last_grad (float): gradient of last epoch\n",
        "            lr (float): current lr\n",
        "            current (float tensor ): global model parameters\n",
        "            target (float tensor): target model parameters\n",
        "            lambd (float): lambda (W) parameter\n",
        "            \"\"\"\n",
        "            boost = 1 if epoch < 200 else 1  # FIXME set 1\n",
        "            # best_attack = _attack(last_grad, lr, current, target)\n",
        "            # attack_loc = best_attack - boost * last_grad / (2 * lambd * nb_nodes * lr)  # malicious not included in \"nb_nodes\"\n",
        "            attack_loc = - last_grad + (current - target) / lr - last_grad / (2 * lambd * nb_nodes * lr)\n",
        "            return attack_loc\n",
        "\n",
        "        # computing attack\n",
        "        with torch.no_grad():\n",
        "            attack_grads = self.get_classifier(self.gpu)\n",
        "            for attack, last_grad, current, target in zip(\n",
        "                    attack_grads.parameters(), \n",
        "                    self.last_honest_grads,\n",
        "                    self.general_model.parameters(),\n",
        "                    self.target_vector.parameters()\n",
        "                ):\n",
        "                for i, (h_grad, curr, targ) in enumerate(zip(last_grad, current, target)):\n",
        "                    if local:  # manipulating avg of local honest models\n",
        "                        attack[i] = _attack_local(h_grad, self.lr_gen, curr, targ, self.nb_nodes, self.weights[0], epoch)\n",
        "                    else:  # manipulating global model\n",
        "                        attack[i] = _attack(h_grad, self.lr_gen, curr, targ)\n",
        "\n",
        "            if self.pow_gen == (2, 0.5):  # if L_2 (not squared norm), attack limited\n",
        "                attack_invnorm = 1 / model_norm(attack_grads, (2, 0.5))\n",
        "                if attack_invnorm < 1 / self.weights[0]:  # if norm > w\n",
        "                    for par in attack_grads.parameters():\n",
        "                        for i, p in enumerate(par):\n",
        "                            par[i] = p * attack_invnorm * self.weights[0]\n",
        "        \n",
        "        # saving honest grads for next epoch\n",
        "        self.last_honest_grads = deepcopy(extract_grad(self.general_model))\n",
        "\n",
        "        # applying attack\n",
        "        for attack, param in zip(attack_grads.parameters(), self.general_model.parameters()):\n",
        "            for i, att in enumerate(attack):\n",
        "                param.grad[i] += att\n",
        "\n",
        "    # ====================  TRAINING ================== \n",
        "\n",
        "    def train(self, nb_epochs=None, test_freq=1, verb=1, schedule=(1,0), gradient_hacking=False, malicious_boost=1):   \n",
        "        \"\"\" training loop \"\"\"\n",
        "        time_train = time()\n",
        "\n",
        "        # initialisation to avoid undefined variables at epoch 1\n",
        "        loss, fit_loss, gen_loss= 0, 0, 0\n",
        "\n",
        "        # training loop \n",
        "        for epoch in range(1, nb_epochs + 1):\n",
        "            if verb: print(\"\\nepoch {}/{}\".format(epoch, nb_epochs))\n",
        "            time_ep = time()\n",
        "            self._zero_opt() # resetting gradients\n",
        "\n",
        "            self._lr_schedule(schedule)\n",
        "            self._set_lr()\n",
        "            \n",
        "            # ------- loss computation --------------------------\n",
        "            fit_loss, gen_loss = 0, 0\n",
        "\n",
        "            for n in range(self.nb_nodes):   # for each node\n",
        "                mult = malicious_boost if n == (self.nb_nodes - 1) else 1 \n",
        "                fit_loss += mult * local_loss(   \n",
        "                    self.models[n], self.data[n], self.labels[n]\n",
        "                )\n",
        "\n",
        "                gen = models_dist(\n",
        "                    self.models[n], self.general_model, self.pow_gen\n",
        "                )\n",
        "\n",
        "                gen_loss += self.weights[n] * gen  # generalisation term   \n",
        "            \n",
        "            loss = fit_loss + gen_loss\n",
        "\n",
        "            # -----------------------------------------------\n",
        "            total_out = round_loss(fit_loss + gen_loss)\n",
        "            if verb >= 2:\n",
        "                self._print_losses(total_out, fit_loss, gen_loss)\n",
        "  \n",
        "            # Gradient descent \n",
        "            loss.backward()\n",
        "\n",
        "            # Malicious counter gradient attack (CGA) if allowed\n",
        "            if gradient_hacking:\n",
        "                self._counter_grad_attack(epoch, local=False)\n",
        "\n",
        "            self._do_all_step()\n",
        " \n",
        "            if verb: \n",
        "                print(\"epoch time :\", round(time() - time_ep, 2)) \n",
        "            self._update_hist(epoch, test_freq, fit_loss, gen_loss, verb)\n",
        "            self._old(1)  # aging all nodes\n",
        "             \n",
        "        # ----------------- end of training -------------------------------  \n",
        "        print(\"training time :\", round(time() - time_train, 2)) \n",
        "        return self.history\n",
        "\n",
        "    # ------------ to check for problems --------------------------\n",
        "    def check(self):\n",
        "        \"\"\" perform some tests on internal parameters adequation \"\"\"\n",
        "        # population check\n",
        "        b1 =  (self.nb_nodes == len(self.data) == len(self.labels) \n",
        "            == len(self.typ) == len(self.models) == len(self.opt_nodes) \n",
        "            == len(self.weights) == len(self.age))\n",
        "        # history check\n",
        "        b2 = True\n",
        "        for l in self.history:\n",
        "            b2 = b2 and (len(l) == len(self.history[0]) >= max(self.age))\n",
        "        if (b1 and b2):\n",
        "            print(\"No Problem\")\n",
        "        else:\n",
        "            print(\"Coherency problem in Flower object\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMatkr4R_iWQ"
      },
      "source": [
        "### flower utility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Mqix5WLBWpCp"
      },
      "outputs": [],
      "source": [
        "def get_flower(gpu=True, target_vector=None, **kwargs):\n",
        "    \"\"\"get a Flower using the appropriate test data (gpu or not)\"\"\"\n",
        "    if gpu:\n",
        "        return Flower(test_gpu_biased, gpu=gpu, target_vector=target_vector, **kwargs)\n",
        "    print(\"cpu version not up to date\")\n",
        "\n",
        "def extract_grad(model):\n",
        "    \"\"\" return list of gradients of a model\"\"\"\n",
        "    l_grad =  [p.grad for p in model.parameters()]\n",
        "    return l_grad\n",
        "\n",
        "def sp(l_grad1, l_grad2):\n",
        "    \"\"\"scalar product of 2 lists of gradients\"\"\"\n",
        "    s = 0\n",
        "    for g1, g2 in zip(l_grad1, l_grad2):\n",
        "        s += (g1 * g2).sum()\n",
        "    return round_loss(s, 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNiOich9viuc"
      },
      "source": [
        "# PLOT FUNCTIONS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SV9TcHxDotZ"
      },
      "source": [
        "## Plotting utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0HdbfF8jDm8R"
      },
      "outputs": [],
      "source": [
        "INTENS = 0.4  # intensity of lines\n",
        "\n",
        "def seedall(s):\n",
        "    \"\"\"seed all sources of randomness\"\"\"\n",
        "    reproducible = (s >= 0)\n",
        "    torch.manual_seed(s)\n",
        "    random.seed(s)\n",
        "    np.random.seed(s)\n",
        "    torch.backends.cudnn.deterministic = reproducible\n",
        "    torch.backends.cudnn.benchmark     = not reproducible\n",
        "    print(\"\\nSeeded all to\", s)\n",
        "\n",
        "def replace_dir(path):\n",
        "    \"\"\" create or replace directory \"\"\"\n",
        "    if os.path.exists(path):\n",
        "        shutil.rmtree(path)\n",
        "    os.makedirs(path)\n",
        "\n",
        "def get_style():\n",
        "    \"\"\"give different line styles for plots\"\"\"\n",
        "    l = [\"-\",\"-.\",\":\",\"--\"]\n",
        "    for i in range(10000):\n",
        "        yield l[i % 4]\n",
        "\n",
        "def get_color():\n",
        "    \"\"\"give different line styles for plots\"\"\"\n",
        "    l = [\"red\",\"green\",\"blue\",\"grey\"]\n",
        "    for i in range(10000):\n",
        "        yield l[i % 4]\n",
        "\n",
        "def set_styles():\n",
        "    \"\"\" sets the global generators variables \"\"\"\n",
        "    global STYLES\n",
        "    global COLORS\n",
        "    STYLES = get_style()\n",
        "    COLORS = get_color()\n",
        "\n",
        "def title_save(title=None, path=None, suff=\".png\"):\n",
        "    \"\"\" add title and save plot \"\"\"\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    if path is not None:\n",
        "        plt.savefig(path + suff, bbox_inches='tight')\n",
        "\n",
        "def legendize(y):\n",
        "    \"\"\" label axis of plt plot \"\"\"\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(y)\n",
        "    plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-b245eNov4b1"
      },
      "source": [
        "## Plotting from history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "a_uPE0aIC0Ai"
      },
      "outputs": [],
      "source": [
        "# functions to display training history \n",
        "\n",
        "def means_bounds(arr):\n",
        "    \"\"\" from array return 1 array of means, \n",
        "        1 of (mean - var), 1 of (mean + var)\n",
        "    \"\"\"\n",
        "    means = np.mean(arr, axis=0)\n",
        "    var = np.var(arr, axis = 0) \n",
        "    low, up = means - var, means + var\n",
        "    return means, low, up\n",
        "\n",
        "# ----------- to display multiple accuracy curves on same plot -----------\n",
        "def add_acc_var(arr, label):\n",
        "    \"\"\" from array add curve of accuracy \"\"\"\n",
        "    acc = arr[:,3,:]\n",
        "    means, low, up = means_bounds(acc)\n",
        "    epochs = range(1, len(means) + 1)\n",
        "    plt.plot(epochs, means, label=label, linestyle=next(STYLES))\n",
        "    plt.fill_between(epochs, up, low, alpha=0.4)\n",
        "\n",
        "# ------------- utility for what follows -------------------------\n",
        "def plot_var(l_hist, l_idx):\n",
        "    \"\"\" add curve of asked indexes of history to the plot \"\"\"\n",
        "    arr_hist = np.asarray(l_hist)\n",
        "    epochs = range(1, arr_hist.shape[2] + 1)\n",
        "    for idx in l_idx:\n",
        "        vals = arr_hist[:,idx,:]\n",
        "        vals_m, vals_l, vals_u = means_bounds(vals)\n",
        "        style, color = next(STYLES), next(COLORS)\n",
        "        plt.plot(epochs, vals_m, label=METRICS[idx][\"lab\"], linestyle=style, color=color)\n",
        "        plt.fill_between(epochs, vals_u, vals_l, alpha=INTENS, color=color)\n",
        "\n",
        "def plotfull_var(l_hist, l_idx, title=None, path=None, show=True):\n",
        "    \"\"\" plot metrics asked in -l_idx and save if -path provided \"\"\"\n",
        "    set_styles()\n",
        "    plot_var(l_hist, l_idx)\n",
        "    idx = l_idx[0]\n",
        "    legendize(METRICS[idx][\"ord\"])\n",
        "    title_save(title, path, suff=\"{}.pdf\".format(METRICS[idx][\"f_name\"]))\n",
        "\n",
        "    if show: \n",
        "        plt.show()\n",
        "\n",
        "# ------- groups of metrics on a same plot -----------\n",
        "def loss_var(l_hist, title=None, path=None):\n",
        "    \"\"\" plot losses with variance from a list of historys \"\"\"\n",
        "    plotfull_var(l_hist, [0, 1], title, path)\n",
        "\n",
        "def acc_var(l_hist, title=None, path=None):\n",
        "    \"\"\" plot accuracy with variance from a list of historys \"\"\"\n",
        "    plt.ylim([0,1])\n",
        "    plt.grid(True, which='major', linewidth=1, axis='y', alpha=1)\n",
        "    plt.minorticks_on()\n",
        "    plt.grid(True, which='minor', linewidth=0.8, axis='y', alpha=0.8)\n",
        "    plotfull_var(l_hist, [3], title, path)\n",
        "\n",
        "def l2_var(l_hist, title=None, path=None):\n",
        "    \"\"\"plot l2 norm of gen model from a list of historys\"\"\"\n",
        "    # plotfull_var(l_hist, [4, 5, 6], title, path)\n",
        "    plotfull_var(l_hist, [6], title, path)\n",
        "\n",
        "def gradsp_var(l_hist, title=None, path=None):\n",
        "    \"\"\" plot scalar product of gradients between 2 consecutive epochs\n",
        "        from a list of historys\n",
        "    \"\"\"\n",
        "    plotfull_var(l_hist, [7], title, path)\n",
        "\n",
        "# plotting all we have\n",
        "def plot_metrics(l_hist, title=None, path=None):\n",
        "    \"\"\"plot and save the different metrics from list of historys\"\"\"\n",
        "    acc_var(l_hist, title, path)  \n",
        "    # loss_var(l_hist, title, path)\n",
        "    l2_var(l_hist, title, path)\n",
        "    # gradsp_var(l_hist, title, path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VOWD2aPGT43"
      },
      "source": [
        "# TRAININGS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_W7IaGlZftL"
      },
      "source": [
        "## Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "EYX8fGagZgJD"
      },
      "outputs": [],
      "source": [
        "# for the model attack\n",
        "\n",
        "def replace_models(flow, l_nodes, model):\n",
        "    \"\"\" replaces models of nodes of l_nodes by model in flow \"\"\"\n",
        "\n",
        "    def _replace(modified, input):\n",
        "        with torch.no_grad():\n",
        "            for par1, par2 in zip(modified.parameters(), input.parameters()):\n",
        "                for i, par in enumerate(par2):\n",
        "                    par1[i] = par  # deepcopy ?\n",
        "    for node in l_nodes:\n",
        "        if node == -1:\n",
        "            _replace(flow.general_model, model)\n",
        "        else:\n",
        "            _replace(flow.models[node], model) \n",
        "\n",
        "# for the data attack\n",
        "\n",
        "def add_noise(model, noise=1):\n",
        "    \"\"\" add noise to the parameters of a model \"\"\"\n",
        "    with torch.no_grad():\n",
        "        for par in model.parameters():\n",
        "            par += torch.normal(torch.zeros_like(par), noise)\n",
        "\n",
        "def get_attacking_data(model, sample_size, noise=1, probas=True, device=DEVICE):\n",
        "    \"\"\" creating equiprobable attacking data \"\"\"\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # creating a basis of the orthogonal of V\n",
        "        def _get_z_a(y_a, l_z):\n",
        "            \"\"\" l_z : list of z_a, a<b \"\"\"\n",
        "            return y_a - sum((y_a @ z_b ) * z_b / (z_b @ z_b) for z_b in l_z)\n",
        "\n",
        "        def _get_c_a_prime(c_a, y_a, l_z, l_c_prime):\n",
        "\n",
        "            return c_a - sum(((y_a @ z_b ) * c_b_prime / (z_b @ z_b)) for z_b, c_b_prime in zip(l_z, l_c_prime))\n",
        "\n",
        "        params, biases = list(model.parameters())\n",
        "        l_y = [params[i] - params[0] for i in range(1, 10)]\n",
        "        l_c = [biases[0] - biases[i] for i in range(1, 10)]\n",
        "        orth_base = [] \n",
        "        constants = []\n",
        "        for i in range(0, 9):\n",
        "            orth_base.append(_get_z_a(l_y[i], orth_base[:i]))\n",
        "\n",
        "        for i in range(0, 9):\n",
        "            constants.append(_get_c_a_prime(l_c[i], l_y[i], orth_base[:i], constants[:i]))\n",
        "\n",
        "        def _proj(x, y, c):\n",
        "            return x - (((x @ y) - c) * y / (y @ y))\n",
        "\n",
        "        def _full_proj(img):\n",
        "            for i in range(0, 9):\n",
        "                img = _proj(img, orth_base[i], constants[i])\n",
        "            return img\n",
        "\n",
        "        orthnorm_base = []\n",
        "        for i in range(9):\n",
        "            orthnorm_base.append(orth_base[i] / math.sqrt(orth_base[i] @ orth_base[i]))\n",
        "\n",
        "        # generating images\n",
        "        num = 1  # number of noised images for each projection\n",
        "        pre_input =  torch.empty((sample_size * num, IMG_SIZE**2), device=device)\n",
        "        for i in range(sample_size):\n",
        "            # image = torch.rand(IMG_SIZE**2, device=device) * 100 - 50\n",
        "            image = torch.rand(IMG_SIZE**2, device=device) * 1 # RMV\n",
        "\n",
        "            proj = _full_proj(image)\n",
        "            for j in range(num):\n",
        "                proj2 = deepcopy(proj)\n",
        "                noises = torch.normal(torch.zeros(9), noise)\n",
        "                for scale, vect in zip(noises, orthnorm_base): # adding noise orthogonal to V\n",
        "                    proj2 += scale * vect \n",
        "                pre_input[i * num + j] = proj2\n",
        "\n",
        "        # getting predictions\n",
        "        input1 = torch.reshape(pre_input, (sample_size * num, 1, IMG_SIZE, IMG_SIZE))\n",
        "\n",
        "        # putting into [0, 1]\n",
        "        # torch.clip_(input1, min=0, max=1) RMV\n",
        "        print('min:', torch.min(input1), 'max:', torch.max(input1))\n",
        "        input1 = input1 / torch.max(input1)  # reduction\n",
        "        torch.clip_(input1, min=0, max=1)\n",
        "\n",
        "        output = model(input1)\n",
        "        \n",
        "        # getting random labels based on output distribution\n",
        "        probs = nn.Softmax(dim=1)(output)\n",
        "\n",
        "    return (input1, probs)       "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heYONUKTjIFL"
      },
      "source": [
        "## Initialisation (Centralised learning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C60FdCxShEEo",
        "outputId": "5c51f4c7-52e4-4f95-ee4b-b1dd9f0744bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Seeded all to 1\n",
            "Added 1 jokers nodes of 60000 data points\n",
            "Total number of nodes : 1\n"
          ]
        }
      ],
      "source": [
        "# Model trained to predict wrong\n",
        "\n",
        "config0 = deepcopy(DEFAULTS)\n",
        "config0['opt'] = optim.Adam\n",
        "config0['w'] = 0  # the model learns independendtly\n",
        "\n",
        "seedall(1)\n",
        "flow_strategic = get_flower(**config0)\n",
        "flow_strategic.add_nodes(train, pop=(1, 60_000), typ='jokers', **config0)\n",
        "hist_strategic = flow_strategic.train(100, verb=0)\n",
        "flow_strategic.check()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWEaHnQ_xkrx"
      },
      "outputs": [],
      "source": [
        "flow_strategic.display(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6sJsk7Gzv5e"
      },
      "outputs": [],
      "source": [
        "# choosing parameters\n",
        "\n",
        "NBH = 2  # number of honest nodes\n",
        "NBDH = 6000  # honest nodes number of data points\n",
        "\n",
        "TARGET = flow_strategic.models[0]  # model learnt above\n",
        "\n",
        "W = 1  # the \"lambda\" parameter\n",
        "\n",
        "NB_EPS = 300  # number of training epochs\n",
        "LR = 0.02  # learning rate\n",
        "SCHEDULE = (0.99, 0.005) # (lr decay, min learning rate)\n",
        "\n",
        "# preparing configuration\n",
        "config = deepcopy(DEFAULTS)\n",
        "config['pow_gen'] = (2, 1)\n",
        "config['w'] = W\n",
        "\n",
        "config['opt'] = optim.Adam\n",
        "config['lr_gen'] = LR\n",
        "config['lr_node'] = LR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbmD5DC1jBIi"
      },
      "source": [
        "## Gradient attack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uON7T6gCI4l"
      },
      "outputs": [],
      "source": [
        "# l2 squared, gradient attack\n",
        "\n",
        "seedall(1) \n",
        "flow_gradient = get_flower(target_vector=TARGET, **config)\n",
        "flow_gradient.add_nodes(train, pop=(NBH, NBDH), typ='honest', **config)\n",
        " \n",
        "# replace_models(flow_gradient, [0], TARGET)  # RMV\n",
        "\n",
        "hist_gradient = flow_gradient.train(NB_EPS, gradient_hacking=True, verb=0, schedule=SCHEDULE)\n",
        "flow_gradient.check()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9zfs0FSArNl"
      },
      "source": [
        "## Model attack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwCzsv5NA1EX"
      },
      "outputs": [],
      "source": [
        "# computing the equivalent model for model attack\n",
        "attacking_model = get_attacking_model(flow_gradient)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6upJzB_9lwu"
      },
      "outputs": [],
      "source": [
        "# l2 squared, model attack\n",
        "\n",
        "seedall(1)\n",
        "flow_model = get_flower(target_vector=TARGET, **config)\n",
        "flow_model.add_nodes(train, pop=(NBH, NBDH), typ='honest', **config)\n",
        "\n",
        "# model attack, the attacking model is freezed\n",
        "flow_model.add_nodes(train, pop=(1, 1), typ='freezed', **config)  \n",
        "replace_models(flow_model, [NBH], attacking_model)\n",
        "\n",
        "hist_model = flow_model.train(NB_EPS, verb=0, schedule=SCHEDULE, gradient_hacking=False)\n",
        "flow_model.check()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOhoK5cdA-Af"
      },
      "source": [
        "## Data attack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EbIDrJwJMdQV"
      },
      "outputs": [],
      "source": [
        "# computing the attacking data\n",
        "attacking_data = get_attacking_data(attacking_model, noise=0.01, sample_size=100_000 * W)  # FIXME 2000 * W"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGE9Zm_2BOG1"
      },
      "outputs": [],
      "source": [
        "# l2 squared, data attack\n",
        "\n",
        "seedall(1)\n",
        "flow_data = get_flower(target_vector=TARGET, **config)\n",
        "flow_data.add_nodes(train, pop=(NBH, NBDH), typ='honest', **config)\n",
        "\n",
        "# data attack\n",
        "flow_data.add_nodes(attacking_data, pop=(1, len(attacking_data[0])), typ='honest', **config)\n",
        "# initialising the attacker's local model close to the attacking model\n",
        "init = deepcopy(attacking_model)\n",
        "add_noise(init, 0.1)  # adding gaussian noise\n",
        "replace_models(flow_data, [NBH], init)\n",
        "\n",
        "hist_data = flow_data.train(NB_EPS, verb=0, schedule=SCHEDULE, gradient_hacking=False, malicious_boost=1000)\n",
        "flow_data.check()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P82AbWAjXvYe"
      },
      "source": [
        "# RESULTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XbzEgr_dtAmk"
      },
      "outputs": [],
      "source": [
        "# accuracys for the malicious model\n",
        "flow_strategic.display(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCl2ZUwqPgy0"
      },
      "outputs": [],
      "source": [
        "# gradient attack\n",
        "plot_metrics([hist_gradient], title='Gradient attack', path='gradient_')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfx0N-Xq-Qt_"
      },
      "outputs": [],
      "source": [
        "# model attack'\n",
        "plot_metrics([hist_model], title='Model attack', path='model_')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4NAHzEXl98L1"
      },
      "outputs": [],
      "source": [
        "# data attack\n",
        "plot_metrics([hist_data], title='Data attack', path='data_')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "2hon_clipped _global_1L.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "01b501ecf8754712b46e1ecbf2440620": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01cd04f61d7f4905956cf99850555654": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "095e7c3824b04fb78cab882e265c6a37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "152409ccc1fc4c96bf35bf66bf24d2c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01cd04f61d7f4905956cf99850555654",
            "placeholder": "",
            "style": "IPY_MODEL_b3351436f7f943cea8d1ff0d97a4067d",
            "value": ""
          }
        },
        "19536edbc74d4cc5b9b80410b9daf2e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01b501ecf8754712b46e1ecbf2440620",
            "max": 28881,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_82ea4af4d5924a9facfb47aa086e0c04",
            "value": 28881
          }
        },
        "27d4fadb3d0d465fb6e0236af333760f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2801b60b98d841c5823e44e833b45e24": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38d1989df8ff40198fdc4706905ee9d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e58803f8cab3478c9815e5676f444ed9",
            "placeholder": "",
            "style": "IPY_MODEL_664c5b198a704567ad1ee6d9f5ec7c9d",
            "value": ""
          }
        },
        "3b33fa117a3c4dd48cdb315daa648979": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b6d4eb48b7b49b8a158d8133e2213f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4841af34ff904dbcb50016a3c51cf662": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b677140bd1cd4035a8b638f9d335373a",
            "placeholder": "",
            "style": "IPY_MODEL_a9a601e7e0f24bb1b717cc4d48f70612",
            "value": ""
          }
        },
        "5ec1a3e004a24aaf8dc71ac0423e7085": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62daef6097d548128888bf32d540d042": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ec1a3e004a24aaf8dc71ac0423e7085",
            "max": 1648877,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ae51cddaed1544a8ac0c88d0beca91ae",
            "value": 1648877
          }
        },
        "664c5b198a704567ad1ee6d9f5ec7c9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "685569bd697540e3bc6cc737e31810af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7aa928fa7b894500a28283a900bb5f2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b68f05dbbd8424195088f1c22fd724d",
            "placeholder": "",
            "style": "IPY_MODEL_a957404a24624d5c9e16344d5e63acee",
            "value": ""
          }
        },
        "7b68f05dbbd8424195088f1c22fd724d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82ea4af4d5924a9facfb47aa086e0c04": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "846393f36b984b6b9effb6ed0fa22474": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87047aaad4f94788ac590e8bbeaf3b50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec0e02e8114142afa0345dc0cf8e6662",
            "placeholder": "",
            "style": "IPY_MODEL_9f71bb085a9d480384ac079e72f4912e",
            "value": " 29696/? [00:00&lt;00:00, 1087086.75it/s]"
          }
        },
        "8f1fa5b6afcd47a787beb817550e58c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4841af34ff904dbcb50016a3c51cf662",
              "IPY_MODEL_19536edbc74d4cc5b9b80410b9daf2e7",
              "IPY_MODEL_87047aaad4f94788ac590e8bbeaf3b50"
            ],
            "layout": "IPY_MODEL_a36307f475f64492acd8edbb752ee2cf"
          }
        },
        "96a37d57901c4934a7fde14f552140a7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c3aba1d39294aeea6e9711a40fe8fd6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ed5f5ef778a4733a63ac1100449f3fa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f71bb085a9d480384ac079e72f4912e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a36307f475f64492acd8edbb752ee2cf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a957404a24624d5c9e16344d5e63acee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9a601e7e0f24bb1b717cc4d48f70612": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae51cddaed1544a8ac0c88d0beca91ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b3351436f7f943cea8d1ff0d97a4067d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b677140bd1cd4035a8b638f9d335373a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7312aba05d24a86a9c1367fbdb83c24": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba95f452c820489490df2309287d4417": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7aa928fa7b894500a28283a900bb5f2e",
              "IPY_MODEL_62daef6097d548128888bf32d540d042",
              "IPY_MODEL_bbc545eac4474e74a8b18622a2604645"
            ],
            "layout": "IPY_MODEL_2801b60b98d841c5823e44e833b45e24"
          }
        },
        "bbc545eac4474e74a8b18622a2604645": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96a37d57901c4934a7fde14f552140a7",
            "placeholder": "",
            "style": "IPY_MODEL_095e7c3824b04fb78cab882e265c6a37",
            "value": " 1649664/? [00:00&lt;00:00, 33456597.15it/s]"
          }
        },
        "c0d19c9cc2c147629003aaf3bd66d309": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ed5f5ef778a4733a63ac1100449f3fa",
            "placeholder": "",
            "style": "IPY_MODEL_3b33fa117a3c4dd48cdb315daa648979",
            "value": " 5120/? [00:00&lt;00:00, 202571.78it/s]"
          }
        },
        "d5cb908ad13c4d609267a32cdcddb856": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da9ef74e4dec47a09da32b4726ab3d78": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_846393f36b984b6b9effb6ed0fa22474",
            "max": 4542,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b7312aba05d24a86a9c1367fbdb83c24",
            "value": 4542
          }
        },
        "dfd7cb6d78e6438b831f481af3a1b6fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e58803f8cab3478c9815e5676f444ed9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec0e02e8114142afa0345dc0cf8e6662": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f474928896464257b2ae2e3c9d5c4832": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_38d1989df8ff40198fdc4706905ee9d3",
              "IPY_MODEL_f92a83522644440193bce44298681c5f",
              "IPY_MODEL_fd3baa779c5440409969bd51781a974d"
            ],
            "layout": "IPY_MODEL_27d4fadb3d0d465fb6e0236af333760f"
          }
        },
        "f92a83522644440193bce44298681c5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c3aba1d39294aeea6e9711a40fe8fd6",
            "max": 9912422,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dfd7cb6d78e6438b831f481af3a1b6fb",
            "value": 9912422
          }
        },
        "fc19a7593f1145409eb7ec773205943f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_152409ccc1fc4c96bf35bf66bf24d2c7",
              "IPY_MODEL_da9ef74e4dec47a09da32b4726ab3d78",
              "IPY_MODEL_c0d19c9cc2c147629003aaf3bd66d309"
            ],
            "layout": "IPY_MODEL_d5cb908ad13c4d609267a32cdcddb856"
          }
        },
        "fd3baa779c5440409969bd51781a974d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b6d4eb48b7b49b8a158d8133e2213f0",
            "placeholder": "",
            "style": "IPY_MODEL_685569bd697540e3bc6cc737e31810af",
            "value": " 9913344/? [00:00&lt;00:00, 38459917.85it/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
