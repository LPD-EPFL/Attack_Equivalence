{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHP6quamKpem"
      },
      "source": [
        "# INITIALISATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-RRW9zgdKv5"
      },
      "outputs": [],
      "source": [
        "from time import time\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from copy import deepcopy\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms.functional import to_pil_image, resize, to_tensor\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcpDqZ1gts-9"
      },
      "outputs": [],
      "source": [
        "DEFAULTS = { \n",
        "            \"w\": 1,   # float >= 0, harmonisation parameter\n",
        "            \"lr_gen\": 0.02,     # float > 0, learning rate of global model\n",
        "            \"lr_node\": 0.02,    # float > 0, learning rate of local models\n",
        "            \"NN\" : \"linear\",     # \"base\" or \"conv\", neural network architecture\n",
        "            \"opt\": optim.Adam,    # any torch optimizer\n",
        "            \"pow_gen\": (2, 1),  # generalisation norm  \n",
        "            }\n",
        "\n",
        "\n",
        "METRICS = ({\"lab\":\"fit\", \"ord\": \"Training Loss\", \"f_name\": \"loss\"}, \n",
        "           {\"lab\":\"gen\", \"ord\": \"Training Loss\", \"f_name\": \"loss\"}, \n",
        "           {\"lab\":\"acc_big\", \"ord\": \"Accuracy\", \"f_name\": \"acc\"},\n",
        "           {\"lab\":\"acc_small\", \"ord\": \"Accuracy\", \"f_name\": \"acc\"}, \n",
        "           {\"lab\":\"l2_dist\", \"ord\": \"l2 norm\", \"f_name\": \"l2dist\"}, \n",
        "           {\"lab\":\"l2_norm\", \"ord\": \"l2 norm\", \"f_name\": \"l2dist\"}, \n",
        "           {\"lab\":\"grad_sp\", \"ord\": \"Scalar Product\", \"f_name\": \"grad\"}, \n",
        "           {\"lab\":\"grad_norm\", \"ord\": \"Scalar Product\", \"f_name\": \"grad\"},\n",
        "           {\"lab\":\"acc_glob\", \"ord\": \"Accuracy\", \"f_name\": \"acc\"},\n",
        "           )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtHuJPre3AdE"
      },
      "outputs": [],
      "source": [
        "os.chdir(\"/content\")\n",
        "os.makedirs(\"distribution\", exist_ok=True)\n",
        "os.chdir(\"/content/distribution\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_Aro-tEK5zL"
      },
      "source": [
        "# DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrwNrcRjghQx"
      },
      "outputs": [],
      "source": [
        "# data hyperparameters\n",
        "DATASET = datasets.FashionMNIST\n",
        "IMG_SIZE = 28\n",
        "NOISE = 0.6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3plCM_hmKD2D"
      },
      "source": [
        "## functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cChzUjVOMNc3"
      },
      "outputs": [],
      "source": [
        "# data import and management\n",
        "\n",
        "def load_mnist(img_size=IMG_SIZE, noise=NOISE):\n",
        "    \"\"\" return data and labels for train and test mnist dataset \"\"\"\n",
        "    #---------------- train data -------------------\n",
        "    mnist_train = DATASET('data', train=True, download=True)\n",
        "    data_train = mnist_train.data\n",
        "    labels_train = [mnist_train[i][1] for i in range(len(data_train))]\n",
        "\n",
        "    pics = []\n",
        "    for pic in data_train:\n",
        "        pic = to_pil_image(pic)\n",
        "        if img_size != 28:\n",
        "            pic = resize(pic, img_size) # Resize image if needed\n",
        "        pic = to_tensor(pic)            # Tensor conversion normalizes in [0,1]\n",
        "        pics.append(pic)\n",
        "    data_train = torch.stack(pics)\n",
        "\n",
        "    #------------------  test data -----------------------\n",
        "    mnist_test = DATASET('data', train=False, download=True)\n",
        "    data_test = mnist_test.data\n",
        "    labels_test = [mnist_test[i][1] for i in range(len(data_test))]\n",
        "\n",
        "    pics = []\n",
        "    for pic in data_test:\n",
        "        pic = to_pil_image(pic)\n",
        "        if img_size != 28:\n",
        "            pic = resize(pic, img_size)   # Resize image if needed\n",
        "        pic = to_tensor(pic)             # Tensor conversion normalizes in [0,1]\n",
        "        pics.append(pic)\n",
        "    data_test = torch.stack(pics)\n",
        "\n",
        "    nb_rd = int(len(labels_train) * noise)  # number of random labels\n",
        "    for i in range(nb_rd):\n",
        "        labels_train[i] = random.randint(0, 9)\n",
        "    return (data_train, labels_train), (data_test,labels_test)\n",
        "\n",
        "def query(datafull, nb, bias=0, fav=0):\n",
        "    \"\"\" return -nb random samples of -datafull \"\"\"\n",
        "    data, labels = datafull\n",
        "    idxs = list(range(len(data)))\n",
        "    l = []\n",
        "    h, w = data[0][0].shape\n",
        "    d = torch.empty(nb, 1, h, w)\n",
        "    if bias == 0:\n",
        "        indexes = random.sample(idxs, nb) # drawing nb random indexes\n",
        "    else :\n",
        "        indexes = []\n",
        "        for i in range(nb):\n",
        "            idx = one_query(labels, idxs, bias, fav)\n",
        "            indexes.append(idx)\n",
        "            idxs.remove(idx) # to draw only once each index max\n",
        "    for k, i in enumerate(indexes): # filling our query\n",
        "        d[k] = data[i]\n",
        "        l.append(labels[i])\n",
        "    return d, l\n",
        "\n",
        "def one_query(labels, idxs, redraws, fav):\n",
        "    \"\"\" labels : list of labels\n",
        "        idxs : list of available indexes\n",
        "        draws an index with a favorite label choice \n",
        "        fav : favorite label\n",
        "        redraws : max nb of random redraws while fav not found\n",
        "    \"\"\"\n",
        "    lab = -1 \n",
        "    while lab != fav and redraws >= 0:\n",
        "        idx = idxs[random.randint(0, len(idxs)-1)]\n",
        "        lab = labels[idx]\n",
        "        redraws -= 1\n",
        "    return idx\n",
        "\n",
        "def list_to_longtens(l):\n",
        "    \"\"\" change a list into the appropriate ground truths type \"\"\"\n",
        "    probas_gt = not (type(l[0]) is int or l[0].shape == 0)\n",
        "    if probas_gt:\n",
        "        tens = torch.empty((len(l), 10))\n",
        "    else:\n",
        "        tens = torch.empty(len(l), dtype=torch.long)\n",
        "    for i, lab in enumerate(l): \n",
        "        tens[i] = lab\n",
        "    return tens\n",
        "\n",
        "def swap(l, n, m):\n",
        "    \"\"\" swap n and m values in l list \"\"\"\n",
        "    return [m if (v==n) else n if (v==m) else v for v in l]\n",
        "\n",
        "\n",
        "def distribute_data_rd(datafull, distrib, fav_lab=(0,0), \n",
        "                       dish=False, dish_lab=0, gpu=True): \n",
        "    \"\"\"draw random data on N nodes following distrib\n",
        "        data, labels : raw data and labels\n",
        "        distrib : int list, list of nb of data points for each node\n",
        "        pref_lab : (prefered label, strength of preference (int))\n",
        "        dish : boolean, if nodes are dishonest \n",
        "        dish_lab : 0 to 4, labelisation method\n",
        "\n",
        "        returns : (list of batches of images, list of batches of labels)\n",
        "    \"\"\"\n",
        "    data, labels = datafull\n",
        "    N = len(distrib)\n",
        "    data_dist = []      # list of len N\n",
        "    labels_dist = []    # list of len N\n",
        "    fav, strength = fav_lab\n",
        "\n",
        "    for n, number in enumerate(distrib): #for each node\n",
        "        d, l = query(datafull, number, strength, fav)\n",
        "        if gpu:\n",
        "            data_dist.append(torch.FloatTensor(d).cuda())\n",
        "        else:\n",
        "            data_dist.append(torch.FloatTensor(d))\n",
        "        if dish:                # if dishonest node\n",
        "\n",
        "            # labels modification\n",
        "            if dish_lab == 0: # random\n",
        "                tens = torch.randint(10, (number,), dtype=torch.long)\n",
        "            elif dish_lab == 1: # zeros\n",
        "                tens = torch.zeros(number, dtype=torch.long)\n",
        "            elif dish_lab == 2: # swap 1-7, \"strats\"\n",
        "                l = swap(l, 1, 7)\n",
        "                tens = list_to_longtens(l)\n",
        "            elif dish_lab == 3: # swap 2 random    \n",
        "                n, m = random.randint(0,9), random.randint(0,9)\n",
        "                l = swap(l, n, m)\n",
        "                tens = list_to_longtens(l)\n",
        "            elif dish_lab == 4: # label +1, \"jokers\"\n",
        "                tens = (list_to_longtens(l) + 1) % 10\n",
        "\n",
        "        else:           # if honest node \n",
        "            tens = list_to_longtens(l) # needed for CrossEntropy later\n",
        "        if gpu:\n",
        "            tens = tens.cuda()\n",
        "\n",
        "        labels_dist.append(tens)\n",
        "\n",
        "    return data_dist, labels_dist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHCoX9RGMtoI"
      },
      "source": [
        "## get data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4inHbdwNgz4"
      },
      "outputs": [],
      "source": [
        "# downloading data\n",
        "if 'train' not in globals(): # to avoid loading data every time\n",
        "    train, test = load_mnist()\n",
        "    if torch.cuda.is_available():\n",
        "        test_gpu = torch.tensor(test[0]).cuda(), torch.tensor(test[1]).cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_HR2r0oK-Am"
      },
      "source": [
        "# MODELS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QclvVEyDa4G"
      },
      "outputs": [],
      "source": [
        "# model architecture (2 options)\n",
        "\n",
        "def get_base_classifier(gpu=True):\n",
        "    \"\"\" returns linear baseline classifier \"\"\"\n",
        "    model = nn.Sequential( \n",
        "        nn.Flatten(),\n",
        "        nn.Linear(IMG_SIZE**2, 10),\n",
        "        )\n",
        "    if gpu:\n",
        "        return model.cuda()\n",
        "    return model\n",
        "\n",
        "def get_2l_classifier(gpu=True):\n",
        "    \"\"\" returns linear baseline classifier \"\"\"\n",
        "    model = nn.Sequential( \n",
        "        nn.Flatten(),\n",
        "        nn.Linear(IMG_SIZE**2, IMG_SIZE**2),\n",
        "        torch.nn.ReLU(),\n",
        "        nn.Linear(IMG_SIZE**2, 10),\n",
        "        )\n",
        "    if gpu:\n",
        "        return model.cuda()\n",
        "    return model\n",
        "\n",
        "MODELS = {\"linear\": get_base_classifier, '2layers': get_2l_classifier}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZ0v-iNHLBr4"
      },
      "source": [
        "# TRAINING STRUCTURE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-q9ec13VV5z"
      },
      "source": [
        "## Losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-PH-0T9rrdr8"
      },
      "outputs": [],
      "source": [
        "# loss and scoring functions \n",
        "\n",
        "def local_loss(model_loc, x, y, reduction='sum'):  \n",
        "    \"\"\" classification loss \"\"\"\n",
        "    loss = nn.CrossEntropyLoss(reduction=reduction)\n",
        "    predicted = model_loc(x)\n",
        "    local = loss(predicted, y)\n",
        "    return local\n",
        "\n",
        "def models_dist(model_loc, model_glob, pow=(1, 1)):  \n",
        "    \"\"\" l1 distance between global and local parameter\n",
        "        will be mutliplied by w_n \n",
        "        pow : (internal power, external power)\n",
        "    \"\"\"\n",
        "    q, p = pow\n",
        "    dist = sum(((theta - rho)**q).abs().sum() for theta, rho in \n",
        "                  zip(model_loc.parameters(), model_glob.parameters()))**p\n",
        "    return dist\n",
        "\n",
        "def model_norm(model_glob, pow=(2,1)): \n",
        "    \"\"\" l2 squared regularisation of global parameter\n",
        "     will be multiplied by w_0 \n",
        "     pow : (internal power, external power)\n",
        "     \"\"\"\n",
        "    q, p = pow\n",
        "    norm = sum((param**q).abs().sum() for param in model_glob.parameters())**p\n",
        "    return norm\n",
        "\n",
        "def round_loss(tens, dec=0): \n",
        "    \"\"\"from an input scalar tensor returns rounded integer\"\"\"\n",
        "    if type(tens)==int or type(tens)==float:\n",
        "        return round(tens, dec)\n",
        "    else:\n",
        "        return round(tens.item(), dec)\n",
        "\n",
        "def tens_count(tens, val):\n",
        "    \"\"\" counts nb of -val in tensor -tens \"\"\"\n",
        "    return len(tens) - round_loss(torch.count_nonzero(tens-val))\n",
        "\n",
        "def score(model, datafull):\n",
        "    \"\"\" returns accuracy provided models, images and GTs \"\"\"\n",
        "    with torch.no_grad():\n",
        "        out = model(datafull[0])\n",
        "        predictions = torch.max(out, 1)[1]\n",
        "        c=0\n",
        "        for a, b in zip(predictions, datafull[1]):\n",
        "            c += int(a==b)\n",
        "        return c/len(datafull[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cC1BWA7Kk99I"
      },
      "source": [
        "## Flower"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMjTiLjZ_nUO"
      },
      "source": [
        "### flower class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CccpUZLozYXm"
      },
      "outputs": [],
      "source": [
        "# nodes repartition\n",
        "\n",
        "class Flower():\n",
        "    \"\"\" Training structure including local models and general one \n",
        "        Allowing to add and remove nodes at will\n",
        "        .pop\n",
        "        .add_nodes\n",
        "        .rem_nodes\n",
        "        .train\n",
        "        .display\n",
        "        .check\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, test, gpu=True, **kwargs):\n",
        "        \"\"\" opt : optimizer\n",
        "            test : test data couple (imgs,labels)\n",
        "        \"\"\"\n",
        "        self.d_test = test\n",
        "        self.gpu = gpu\n",
        "\n",
        "        self.opt = kwargs[\"opt\"]\n",
        "        self.lr_node = kwargs[\"lr_node\"]\n",
        "        self.lr_gen = kwargs[\"lr_gen\"]\n",
        "\n",
        "        self.get_classifier = MODELS[kwargs[\"NN\"]]\n",
        "        self.general_model = self.get_classifier(gpu)\n",
        "        self.init_model = deepcopy(self.general_model)\n",
        "        self.last_grad = None\n",
        "        self.opt_gen = self.opt(self.general_model.parameters(), lr=self.lr_gen)\n",
        "        self.pow_gen = kwargs[\"pow_gen\"]  # choice of norms for Licchavi loss\n",
        "        self.data = []\n",
        "        self.labels = [] \n",
        "        self.typ = []\n",
        "        self.models = []\n",
        "        self.weights = []\n",
        "        self.age = []\n",
        "        self.opt_nodes = []\n",
        "        self.nb_nodes = 0\n",
        "        self.dic = {\"honest\" : -1, \"trolls\" : 0, \"zeros\" : 1, \n",
        "                    \"one_evil\" : 2, \"strats\" : 3, \"jokers\" : 4, \"byzantine\" : -1,\n",
        "                    'freezed' : -1}\n",
        "        self.history = ([], [], [], [], [], [], [], [], []) \n",
        "        # (\"fit\", \"gen\", \"acc_big\", \"acc_small\", \"l2_dist\", \"l2_norm\", \"grad_sp\", \"grad_norm\", \"acc_glob\")\n",
        "\n",
        "    # ------------ population methods --------------------\n",
        "\n",
        "    def add_nodes(self, datafull, pop, typ, fav_lab=(0,0), verb=1, **kwargs):\n",
        "        \"\"\" add nodes to the Flower \n",
        "            datafull : data to put on node (sampled from it)\n",
        "            pop : (nb of nodes, size of nodes)\n",
        "            typ : type of nodes (str keywords)\n",
        "            fav_lab : (favorite label, strength)\n",
        "            w : int, weight of new nodes\n",
        "        \"\"\"\n",
        "        w = kwargs[\"w\"] # taking global variable if -w not provided\n",
        "        nb, size = pop\n",
        "        id = self.dic[typ]\n",
        "        dish = (id != -1) # boolean for dishonesty\n",
        "        dt, lb = distribute_data_rd(datafull, [size] * nb, fav_lab,\n",
        "                                    dish, dish_lab=id, gpu=self.gpu)\n",
        "        self.data += dt\n",
        "        self.labels += lb\n",
        "        self.typ += [typ] * nb\n",
        "\n",
        "        self.models += [self.get_classifier(self.gpu) for i in range(nb)]\n",
        "        self.weights += [w] * nb\n",
        "        self.age += [0] * nb\n",
        "        self.nb_nodes += nb\n",
        "        self.opt_nodes += [self.opt(self.models[n].parameters(), lr=self.lr_node) \n",
        "            for n in range(self.nb_nodes - nb, self.nb_nodes) \n",
        "            ]\n",
        "        if verb:\n",
        "            print(\"Added {} {} nodes of {} data points\".format(nb, typ, size))\n",
        "            print(\"Total number of nodes : {}\".format(self.nb_nodes))\n",
        "\n",
        "    def rem_nodes(self, first, last, verb=1):\n",
        "        \"\"\" remove nodes of indexes -first (included) to -last (excluded) \"\"\"\n",
        "        nb = last - first\n",
        "        if last > self.nb_nodes:\n",
        "            print(\"-last is out of range, remove canceled\")\n",
        "        else:\n",
        "            del self.data[first : last]\n",
        "            del self.labels[first : last] \n",
        "            del self.typ[first : last]\n",
        "            del self.models[first : last]\n",
        "            del self.weights[first : last]\n",
        "            del self.age[first : last]\n",
        "            del self.opt_nodes[first : last]\n",
        "            self.nb_nodes -= nb\n",
        "            if verb: print(\"Removed {} nodes\".format(nb))\n",
        "        \n",
        "    def hm(self, ty):\n",
        "        \"\"\" count nb of nodes of this type \"\"\"\n",
        "        return self.typ.count(ty)\n",
        "    \n",
        "    def pop(self):\n",
        "        \"\"\" return dictionnary of population \"\"\"\n",
        "        c = {}\n",
        "        for ty in self.dic.keys():\n",
        "            c[ty] = self.hm(ty)\n",
        "        return c\n",
        "\n",
        "    # ------------- scoring methods -----------\n",
        "    def score_glob(self, datafull): \n",
        "        \"\"\" return accuracy provided images and GTs \"\"\"\n",
        "        return score(self.general_model, datafull)\n",
        "    \n",
        "    def score_loc(self, node):\n",
        "        \"\"\" score of node on global test data \"\"\"\n",
        "        return score(self.models[node], self.d_test)\n",
        "\n",
        "    def score_nodes(self, l_nodes):\n",
        "        \"\"\" mean local test scores of nodes \"\"\"\n",
        "        score_tot = 0\n",
        "        for node in l_nodes:\n",
        "            score_tot += score(self.models[node], self.d_test)\n",
        "        return score_tot / len(l_nodes)\n",
        "\n",
        "    def test_train(self, node):\n",
        "        \"\"\" score of node on its train data \"\"\"\n",
        "        return score(self.models[node], (self.data[node], self.labels[node]))\n",
        "\n",
        "    def display(self, node):\n",
        "        \"\"\" display accuracy for selected node\n",
        "            node = -1 for global model\n",
        "        \"\"\"\n",
        "        if node == -1: # global model\n",
        "            print(\"global model\")\n",
        "            print(\"accuracy on test data :\", \n",
        "                  self.score_glob(self.d_test))\n",
        "        else: # we asked for a node\n",
        "            loc_train = self.test_train(node)\n",
        "            full_test = self.score_loc(node)\n",
        "            print(\"node number :\", node, \", dataset size :\",\n",
        "                len(self.labels[node]), \", type :\", self.typ[node], \n",
        "                \", age :\", self.age[node])\n",
        "            print(\"accuracy on local train data :\", loc_train)\n",
        "            print(\"accuracy on global test data :\", full_test)\n",
        "            repart = {str(k) : tens_count(self.labels[node], k) \n",
        "                for k in range(10)}\n",
        "            print(\"labels repartition :\", repart)\n",
        "    \n",
        "    # ---------- methods for training ------------\n",
        "    def _lr_schedule(self, schedule):\n",
        "        \"\"\" changes learning rates during trainning \"\"\"\n",
        "        decay, lr_min = schedule\n",
        "        if self.lr_node >= lr_min / decay:\n",
        "            self.lr_node *= decay\n",
        "            self.lr_gen *= decay\n",
        "\n",
        "    def _set_lr(self, reduction):\n",
        "        \"\"\"set learning rates of optimizers according to Flower setting\"\"\"\n",
        "        for n in range(self.nb_nodes):\n",
        "            self.opt_nodes[n].param_groups[0]['lr'] = self.lr_node\n",
        "        self.opt_gen.param_groups[0]['lr'] = self.lr_gen\n",
        "\n",
        "    def _zero_opt(self):\n",
        "        \"\"\"reset gradients of all models\"\"\"\n",
        "        for n in range(self.nb_nodes):\n",
        "            self.opt_nodes[n].zero_grad()      \n",
        "        self.opt_gen.zero_grad()\n",
        "\n",
        "    def _update_hist(self, epoch, test_freq, fit, gen, verb=1):\n",
        "        \"\"\" update history \"\"\"\n",
        "        acc_small = self.score_loc(0)\n",
        "        acc_big = self.score_loc(self.nb_nodes - 1)\n",
        "        acc_glob = self.score_glob(self.d_test)\n",
        "        self.history[2].append(acc_big) \n",
        "        self.history[3].append(acc_small) \n",
        "        self.history[8].append(acc_glob) \n",
        "        self.history[0].append(round_loss(fit))\n",
        "        self.history[1].append(round_loss(gen))\n",
        "\n",
        "        dist = models_dist(self.init_model, self.general_model, pow=(2,0.5)) \n",
        "        norm = model_norm(self.general_model, pow=(2,0.5))\n",
        "        self.history[4].append(round_loss(dist, 1))\n",
        "        self.history[5].append(round_loss(norm, 1))\n",
        "        grad_gen = extract_grad(self.general_model)\n",
        "        if epoch > 1: # no last model for first epoch\n",
        "            scal_grad = sp(self.last_grad, grad_gen)\n",
        "            self.history[6].append(scal_grad)\n",
        "        else:\n",
        "            self.history[6].append(0) # default value for first epoch\n",
        "        self.last_grad = deepcopy(extract_grad(self.general_model)) \n",
        "        grad_norm = math.sqrt(sp(grad_gen, grad_gen))\n",
        "        self.history[7].append(grad_norm)\n",
        "\n",
        "    def _old(self, years):\n",
        "        \"\"\" increment age (after training) \"\"\"\n",
        "        for i in range(self.nb_nodes):\n",
        "            self.age[i] += years\n",
        "    \n",
        "    def _do_all_step(self):\n",
        "        for n in range(self.nb_nodes): \n",
        "            self.opt_nodes[n].step()\n",
        "        self.opt_gen.step() \n",
        "\n",
        "    def _print_losses(self, tot, fit, gen):\n",
        "        \"\"\"print losses\"\"\"\n",
        "        print(\"total loss : \", tot) \n",
        "        print(\"fitting : \", round_loss(fit),\n",
        "                ', generalisation : ', round_loss(gen))\n",
        "    # ====================  TRAINING ================== \n",
        "\n",
        "    def train(\n",
        "            self, nb_epochs=None, test_freq=1, verb=1, \n",
        "            reduction='sum', schedule=(1, 0)):   \n",
        "        \"\"\"training loop\"\"\"\n",
        "        # nb_epochs = EPOCHS if nb_epochs is None else nb_epochs\n",
        "        time_train = time()\n",
        "\n",
        "        # initialisation to avoid undefined variables at epoch 1\n",
        "        loss, fit_loss, gen_loss = 0, 0, 0\n",
        "        c_fit, c_gen = 0, 0\n",
        "\n",
        "        # training loop \n",
        "        for epoch in range(1, nb_epochs + 1):\n",
        "            if verb: print(\"\\nepoch {}/{}\".format(epoch, nb_epochs))\n",
        "            time_ep = time()\n",
        "            self._zero_opt() # resetting gradients\n",
        "\n",
        "            self._lr_schedule(schedule)\n",
        "            self._set_lr(reduction)\n",
        "            \n",
        "            # ------- loss computation --------------------------\n",
        "            fit_loss, gen_loss = 0, 0\n",
        "            \n",
        "            for n in range(self.nb_nodes):   # for each node\n",
        "                fit_loss += local_loss(\n",
        "                    self.models[n], self.data[n], self.labels[n], reduction\n",
        "                )\n",
        "\n",
        "                gen = models_dist(\n",
        "                    self.models[n], self.general_model, self.pow_gen\n",
        "                )\n",
        "\n",
        "                gen_loss += self.weights[n] * gen  # generalisation term\n",
        "            if reduction == 'sum':  # harmonisation to better compare\n",
        "                fit_loss /= (sum(len(data) for data in self.data) / self.nb_nodes) # mean of data points per node\n",
        "            loss = fit_loss + gen_loss\n",
        "\n",
        "            # -----------------------------------------------\n",
        "            total_out = round_loss(fit_loss + gen_loss)\n",
        "            if verb >= 2:\n",
        "                self._print_losses(total_out, fit_loss, gen_loss)\n",
        "            # Gradient descent \n",
        "            loss.backward()\n",
        "            self._do_all_step()\n",
        " \n",
        "            if verb: \n",
        "                print(\"epoch time :\", round(time() - time_ep, 2)) \n",
        "            self._update_hist(epoch, test_freq, fit_loss, gen_loss, verb)\n",
        "            self._old(1)  # aging all nodes\n",
        "             \n",
        "        # ----------------- end of training -------------------------------  \n",
        "        for i in range(nb_epochs % test_freq): # to maintain same history length\n",
        "            self.history[3].append(acc)\n",
        "        print(\"training time :\", round(time() - time_train, 2)) \n",
        "        return self.history\n",
        "\n",
        "    # ------------ to check for problems --------------------------\n",
        "    def check(self):\n",
        "        \"\"\" perform some tests on internal parameters adequation \"\"\"\n",
        "        # population check\n",
        "        b1 =  (self.nb_nodes == len(self.data) == len(self.labels) \n",
        "            == len(self.typ) == len(self.models) == len(self.opt_nodes) \n",
        "            == len(self.weights) == len(self.age))\n",
        "        # history check\n",
        "        b2 = True\n",
        "        for l in self.history:\n",
        "            b2 = b2 and (len(l) == len(self.history[0]) >= max(self.age))\n",
        "        if (b1 and b2):\n",
        "            print(\"No Problem\")\n",
        "        else:\n",
        "            print(\"Coherency problem in Flower object\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMatkr4R_iWQ"
      },
      "source": [
        "### flower utility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mqix5WLBWpCp"
      },
      "outputs": [],
      "source": [
        "def get_flower(gpu=True, **kwargs):\n",
        "    \"\"\"get a Flower using the appropriate test data (gpu or not)\"\"\"\n",
        "    if gpu:\n",
        "        return Flower(test_gpu, gpu=gpu, **kwargs)\n",
        "    return Flower(test, gpu=gpu, **kwargs)\n",
        "\n",
        "def extract_grad(model):\n",
        "    \"\"\"return list of gradients of a model\"\"\"\n",
        "    l_grad =  [p.grad for p in model.parameters()]\n",
        "    return l_grad\n",
        "\n",
        "def sp(l_grad1, l_grad2):\n",
        "    \"\"\"scalar product of 2 lists of gradients\"\"\"\n",
        "    s = 0\n",
        "    for g1, g2 in zip(l_grad1, l_grad2):\n",
        "        s += (g1 * g2).sum()\n",
        "    return round_loss(s, 4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNiOich9viuc"
      },
      "source": [
        "# PLOTTING FUNCTIONS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SV9TcHxDotZ"
      },
      "source": [
        "## Plotting utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HdbfF8jDm8R"
      },
      "outputs": [],
      "source": [
        "INTENS = 0.4  # intensity of sublines\n",
        "\n",
        "def seedall(s):\n",
        "    \"\"\"seed all sources of randomness\"\"\"\n",
        "    reproducible = (s >= 0)\n",
        "    torch.manual_seed(s)\n",
        "    random.seed(s)\n",
        "    np.random.seed(s)\n",
        "    torch.backends.cudnn.deterministic = reproducible\n",
        "    torch.backends.cudnn.benchmark     = not reproducible\n",
        "    print(\"\\nSeeded all to\", s)\n",
        "\n",
        "def replace_dir(path):\n",
        "    \"\"\" create or replace directory \"\"\"\n",
        "    if os.path.exists(path):\n",
        "        shutil.rmtree(path)\n",
        "    os.makedirs(path)\n",
        "\n",
        "def get_style():\n",
        "    \"\"\"give different line styles for plots\"\"\"\n",
        "    l = [\"-\",\"-.\",\":\",\"--\"]\n",
        "    for i in range(10000):\n",
        "        yield l[i % 4]\n",
        "\n",
        "def get_color():\n",
        "    \"\"\"give different line styles for plots\"\"\"\n",
        "    l = [\"red\",\"green\",\"blue\",\"grey\"]\n",
        "    for i in range(10000):\n",
        "        yield l[i % 4]\n",
        "\n",
        "def set_styles():\n",
        "    \"\"\" sets the global generators variables \"\"\"\n",
        "    global STYLES\n",
        "    global COLORS\n",
        "    STYLES = get_style() \n",
        "    COLORS = get_color()\n",
        "\n",
        "def title_save(title=None, path=None, suff=\".pdf\"):\n",
        "    \"\"\" add title and save plot \"\"\"\n",
        "    if title is not None:   \n",
        "        plt.title(title)\n",
        "    if path is not None:\n",
        "        plt.savefig(path + suff, bbox_inches='tight')\n",
        "\n",
        "def legendize(y):\n",
        "    \"\"\" label axis of plt plot \"\"\"\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(y)\n",
        "    plt.legend()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-b245eNov4b1"
      },
      "source": [
        "## Plotting from history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_uPE0aIC0Ai"
      },
      "outputs": [],
      "source": [
        "# functions to display training history \n",
        "\n",
        "def means_bounds(arr):\n",
        "    \"\"\" from array return 1 array of means, \n",
        "        1 of (mean - var), 1 of (mean + var)\n",
        "    \"\"\"\n",
        "    means = np.mean(arr, axis=0)\n",
        "    var = np.var(arr, axis = 0) \n",
        "    low, up = means - var, means + var\n",
        "    return means, low, up\n",
        "\n",
        "# ----------- to display multiple accuracy curves on same plot -----------\n",
        "def add_acc_var(arr, label):\n",
        "    \"\"\" from array add curve of accuracy \"\"\"\n",
        "    acc = arr[:,3,:]\n",
        "    means, low, up = means_bounds(acc)\n",
        "    epochs = range(1, len(means) + 1)\n",
        "    plt.plot(epochs, means, label=label, linestyle=next(STYLES))\n",
        "    plt.fill_between(epochs, up, low, alpha=0.4)\n",
        "\n",
        "# ------------- utility for what follows -------------------------\n",
        "def plot_var(l_hist, l_idx):\n",
        "    \"\"\" add curve of asked indexes of history to the plot \"\"\"\n",
        "    arr_hist = np.asarray(l_hist)\n",
        "    epochs = range(1, arr_hist.shape[2] + 1)\n",
        "    for idx in l_idx:\n",
        "        vals = arr_hist[:,idx,:]\n",
        "        vals_m, vals_l, vals_u = means_bounds(vals)\n",
        "        style, color = next(STYLES), next(COLORS)\n",
        "        plt.plot(epochs, vals_m, label=METRICS[idx][\"lab\"], linestyle=style, color=color)\n",
        "        plt.fill_between(epochs, vals_u, vals_l, alpha=INTENS, color=color)\n",
        "\n",
        "def plotfull_var(l_hist, l_idx, title=None, path=None, show=True):\n",
        "    \"\"\" plot metrics asked in -l_idx and save if -path provided \"\"\"\n",
        "    plot_var(l_hist, l_idx)\n",
        "    idx = l_idx[0]\n",
        "    legendize(METRICS[idx][\"ord\"])\n",
        "    title_save(title, path, suff=\"{}.pdf\".format(METRICS[idx][\"f_name\"]))\n",
        "    if show: \n",
        "        plt.show()\n",
        "\n",
        "# ------- groups of metrics on a same plot -----------\n",
        "def loss_var(l_hist, title=None, path=None):\n",
        "    \"\"\" plot losses with variance from a list of historys \"\"\"\n",
        "    plotfull_var(l_hist, [0,1], title, path)\n",
        "\n",
        "def acc_var(l_hist, title=None, path=None):\n",
        "    \"\"\" plot accuracy with variance from a list of historys \"\"\"\n",
        "    plt.ylim([0,1])\n",
        "    plt.grid(True, which='major', linewidth=1, axis='y', alpha=1)\n",
        "    plt.minorticks_on()\n",
        "    plt.grid(True, which='minor', linewidth=0.8, axis='y', alpha=0.8)\n",
        "    plotfull_var(l_hist, [2, 3, 8], title, path)\n",
        "\n",
        "def l2_var(l_hist, title=None, path=None):\n",
        "    \"\"\"plot l2 norm of gen model from a list of historys\"\"\"\n",
        "    plotfull_var(l_hist, [4,5], title, path)\n",
        "\n",
        "def gradsp_var(l_hist, title=None, path=None):\n",
        "    \"\"\" plot scalar product of gradients between 2 consecutive epochs\n",
        "        from a list of historys\n",
        "    \"\"\"\n",
        "    plotfull_var(l_hist, [6,7], title, path)\n",
        "\n",
        "# plotting all we have\n",
        "def plot_metrics(l_hist, title=None, path=None):\n",
        "    \"\"\"plot and save the different metrics from list of historys\"\"\"\n",
        "    set_styles()\n",
        "    acc_var(l_hist, title, path)  \n",
        "    # loss_var(l_hist, title, path)\n",
        "    # l2_var(l_hist, title, path)\n",
        "    # gradsp_var(l_hist, title, path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VOWD2aPGT43"
      },
      "source": [
        "# TRAININGS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqi8ofcjnd4X"
      },
      "outputs": [],
      "source": [
        "def replace_models(flow, l_nodes, model):\n",
        "    \"\"\" replaces models of nodes of l_nodes by model in flow \"\"\"\n",
        "    with torch.no_grad():\n",
        "        for node in l_nodes:\n",
        "            for par1, par2 in zip(flow.models[node].parameters(), model.parameters()):\n",
        "                for i, par in enumerate(par2):\n",
        "                    par1[i] = par  # deepcopy ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6sJsk7Gzv5e"
      },
      "outputs": [],
      "source": [
        "# choosing parameters\n",
        "\n",
        "NB_SMALL = 10  # number of \"idle\" users\n",
        "SMALL_SIZE = 10  # number of data points per idle user\n",
        "NB_BIG = 1  # number of \"active\" users\n",
        "BIG_SIZE = 60_000  # number of data points per active user\n",
        "W = 100  # the \"lambda\" parameter\n",
        "\n",
        "NB_EPS = 200  # number of training epochs\n",
        "LR = 0.04  # learning rate\n",
        "SCHEDULE = (0.99, 0.02)  # (lr decay, min learning rate)\n",
        "OPT = optim.Adam  # optimizer\n",
        "\n",
        "MODEL = '2layers'  # model used (\"linear\" or \"2layers\")\n",
        "\n",
        "# setting configuration\n",
        "config = deepcopy(DEFAULTS)\n",
        "config['opt'] = OPT\n",
        "config['pow_gen'] = (2, 1)  # regularisation norm \n",
        "config['w'] = W\n",
        "\n",
        "config['NN'] = MODEL\n",
        "config['lr_gen'] = LR\n",
        "config['lr_node'] = LR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uON7T6gCI4l",
        "outputId": "0d0fc123-73b4-4474-eeff-fce15a4af52e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Seeded all to 999\n",
            "Added 10 honest nodes of 10 data points\n",
            "Total number of nodes : 10\n",
            "Added 1 honest nodes of 60000 data points\n",
            "Total number of nodes : 11\n",
            "training time : 150.11\n",
            "No Problem\n"
          ]
        }
      ],
      "source": [
        "# AVERAGE\n",
        "\n",
        "seedall(999)\n",
        "flow_average = get_flower(**config)\n",
        "flow_average.add_nodes(train, pop=(NB_SMALL, SMALL_SIZE), typ='honest', **config)\n",
        "flow_average.add_nodes(train, pop=(NB_BIG, BIG_SIZE), typ='honest', **config)\n",
        "\n",
        "hist_average = flow_average.train(NB_EPS, verb=0, reduction='mean', schedule=SCHEDULE)\n",
        "flow_average.check()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vta8U6beYrVs",
        "outputId": "6de9ec2e-342f-44ba-a081-c0bc2dbe9c7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Seeded all to 999\n",
            "Added 10 honest nodes of 10 data points\n",
            "Total number of nodes : 10\n",
            "Added 1 honest nodes of 60000 data points\n",
            "Total number of nodes : 11\n",
            "training time : 150.02\n",
            "No Problem\n"
          ]
        }
      ],
      "source": [
        "# SUM\n",
        "\n",
        "seedall(999)\n",
        "flow_sum = get_flower(**config)\n",
        "flow_sum.add_nodes(train, pop=(NB_SMALL, SMALL_SIZE), typ='honest', **config)\n",
        "flow_sum.add_nodes(train, pop=(NB_BIG, BIG_SIZE), typ='honest', **config)\n",
        "\n",
        "hist_sum = flow_sum.train(NB_EPS, verb=0, reduction='sum', schedule=SCHEDULE)\n",
        "flow_sum.check()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEtOUhaAuO-z"
      },
      "source": [
        "# RESULTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpLb30H_Foua",
        "outputId": "b6f672d0-1c8a-48f1-fad0-ded5371ce01b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AVERAGE\n",
            "global model\n",
            "accuracy on test data : 0.2629\n",
            "SUM\n",
            "global model\n",
            "accuracy on test data : 0.5811\n",
            "\n",
            "Local accuracys\n",
            "AVERAGE SUM\n",
            "small nodes\n",
            "0.2631 0.5805\n",
            "0.2573 0.5806\n",
            "0.2677 0.5807\n",
            "0.2625 0.5806\n",
            "0.2622 0.5807\n",
            "0.2582 0.5807\n",
            "0.2639 0.5806\n",
            "0.2625 0.5806\n",
            "0.2681 0.5807\n",
            "0.2681 0.5805\n",
            "big node\n",
            "0.2642 0.5876\n",
            "\n",
            "Average accuracys\n",
            "average small : 0.26336 sum small : 0.5806200000000001\n",
            "average big : 0.2642 sum big : 0.5876\n"
          ]
        }
      ],
      "source": [
        "# accuracy of global models\n",
        "print('AVERAGE')\n",
        "flow_average.display(-1)\n",
        "print('SUM')\n",
        "flow_sum.display(-1)\n",
        "\n",
        "# mean local accuracy of honest nodes\n",
        "average_small, average_big, sum_small, sum_big = 0, 0, 0, 0\n",
        "\n",
        "print('\\nLocal accuracys')\n",
        "print('AVERAGE', 'SUM')\n",
        "print('small nodes')\n",
        "for node in range(NB_SMALL):\n",
        "    average_s, sum_s = flow_average.score_nodes([node]), flow_sum.score_nodes([node])\n",
        "    print(average_s, sum_s)\n",
        "    average_small += average_s\n",
        "    sum_small += sum_s\n",
        "\n",
        "print('big node')\n",
        "for node in range(NB_SMALL, NB_SMALL + NB_BIG):\n",
        "    average_b, sum_b = flow_average.score_nodes([node]), flow_sum.score_nodes([node])\n",
        "    print(average_b, sum_b)\n",
        "    average_big += average_b\n",
        "    sum_big += sum_b\n",
        "\n",
        "print('\\nAverage accuracys')\n",
        "print(f'average small : {average_small / NB_SMALL}', f'sum small : {sum_small / NB_SMALL}')\n",
        "print(f'average big : {average_big / NB_BIG}', f'sum big : {sum_big / NB_BIG}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXDn8ig7oUxB",
        "outputId": "b0c55697-cc1d-45f4-dc0d-dd335a01fc2d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_metrics([hist_average], title='', path= str(W).replace('.', '') + 'average_')  # FIXME add title"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLWb56R_leUF",
        "outputId": "60ccd566-14dc-479a-9c6c-90fe96c49bd3"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_metrics([hist_sum], title='', path= str(W).replace('.', '') + 'sum_') # FIXME add title"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Propre distribution sum_vs_avg.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
